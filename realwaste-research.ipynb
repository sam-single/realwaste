{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlVFupaOpSvw"
      },
      "source": [
        "\n",
        "# RealWaste Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t-2rgYg6GW-"
      },
      "source": [
        "*Dataset Splitting, Pre-Processing, and Augmentation*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WQ0FkH_bxdv"
      },
      "outputs": [],
      "source": [
        "# Install augmentor library for geometric augmentations\n",
        "!pip install Augmentor\n",
        "# Import directory navigation libraries\n",
        "from os import listdir, rmdir\n",
        "# Import image preprocessing libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "from shutil import move, copy\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "from tensorflow.image import resize\n",
        "from tensorflow.io import decode_jpeg, encode_jpeg, write_file\n",
        "from tensorflow.dtypes import saturate_cast\n",
        "from random import randint\n",
        "# Import augmentor for geometric data augmentations\n",
        "import Augmentor\n",
        "# Import Colab runtime disconnection\n",
        "from google.colab import runtime\n",
        "# Import sleep to allow time for copying to process\n",
        "from time import sleep\n",
        "\n",
        "# ------------------------------- Constants -------------------------------- #\n",
        "# Original dataset path\n",
        "real_waste_original_path = ''\n",
        "# RealWaste training and validation paths\n",
        "real_waste_training_path = ''\n",
        "real_waste_validation_path = ''\n",
        "# RealWaste temporary training and validation paths for augmentation stages\n",
        "temp_real_waste_training_path = ''\n",
        "temp_real_waste_validation_path = ''\n",
        "# Test path\n",
        "test_path = ''\n",
        "# Labels\n",
        "labels = ['Cardboard', 'Food Organics', 'Glass', 'Metal', 'Paper', 'Plastic', 'Miscellaneous Trash', 'Textile Trash', 'Vegetation']\n",
        "# Processed image dimensions\n",
        "img_height = 524\n",
        "img_width = 524\n",
        "\n",
        "# ------------------------------- Functions -------------------------------- #\n",
        "# Count images in directory\n",
        "def count_images(path):\n",
        "    directory = listdir(path)\n",
        "    return len(directory)\n",
        "\n",
        "# Split datasets into training, validation and testing\n",
        "def split_dataset(input_path, train_path, val_path, test_path, val_prop, test_prop, label):\n",
        "    # Count images in directory and get files names\n",
        "    num_files = count_images(input_path+label)\n",
        "    file_names = listdir(input_path+label)\n",
        "\n",
        "    # Calculated number of validation and testing images\n",
        "    num_val = round(num_files*val_prop)\n",
        "    num_test = round(num_files*test_prop)\n",
        "    \n",
        "    # Initialise empty lists for image indexes\n",
        "    val_list = []\n",
        "    test_list = []\n",
        "    \n",
        "    # Randomly assign file indexes for validation dataset\n",
        "    i = 0\n",
        "    while i < num_val:\n",
        "        r = randint(1, num_files - 1)\n",
        "        if r not in val_list:\n",
        "            val_list.append(r)\n",
        "            i += 1\n",
        "\n",
        "    # Move validation dataset files and rename\n",
        "    name_incrementer = 1\n",
        "    for j in val_list:\n",
        "        copy(input_path+label+'/'+file_names[j], val_path+label+'/'+label+'_'+str(name_incrementer)+'.jpg')\n",
        "        sleep(0.05)\n",
        "        name_incrementer += 1\n",
        "    \n",
        "    # Randomly assign file indexes for testing dataset\n",
        "    i = 0\n",
        "    while i < num_test:\n",
        "        r = randint(1, num_files - 1)\n",
        "        if r not in test_list and r not in val_list:\n",
        "            test_list.append(r)\n",
        "            i += 1\n",
        "\n",
        "    # Move test dataset files and rename\n",
        "    name_incrementer = 1\n",
        "    for j in test_list:\n",
        "        copy(input_path+label+'/'+file_names[j], test_path+label+'/'+label+'_'+str(name_incrementer)+'.jpg')\n",
        "        sleep(0.05)\n",
        "        name_incrementer += 1\n",
        "    \n",
        "    # Move remaining files into training dataset\n",
        "    i = 0\n",
        "    while i < num_files:\n",
        "        if i not in val_list and i not in test_list:\n",
        "            copy(input_path+label+'/'+file_names[i], train_path+label+'/'+label+'_'+str(name_incrementer)+'.jpg')\n",
        "            sleep(0.05)\n",
        "            name_incrementer += 1\n",
        "        i += 1\n",
        "\n",
        "# Resize images\n",
        "def resize_image(path, width, height):\n",
        "    directory = listdir(path)\n",
        "    for file in directory:\n",
        "        # Read image as binary file\n",
        "        image = open(path+'/'+file, 'rb')                          \n",
        "        binary_representation = image.read()                        \n",
        "        decoded_representation = decode_jpeg(binary_representation) \n",
        "        # Resize binary represnetation\n",
        "        resized_image = resize(decoded_representation, [width, height])\n",
        "        resized_image = saturate_cast(resized_image, 'uint8')\n",
        "        encoded_image = encode_jpeg(resized_image)                  \n",
        "        write_file(path+'/'+file, encoded_image)\n",
        "        sleep(0.05)\n",
        "\n",
        "# Check images for RGB mode and convert if required\n",
        "def convert_rgb_images(path):\n",
        "    print(path)\n",
        "    directory = listdir(path)\n",
        "    for file in directory:\n",
        "        img = Image.open(path+'/'+file)\n",
        "        # Convert to RGB mode if not already in format\n",
        "        if img.mode != 'RGB':\n",
        "            img.convert('RGB').save(path+'/'+file)\n",
        "            sleep(0.05)\n",
        "            \n",
        "# Geometric augmentation function: distort and flip\n",
        "def distort_and_flip(path):\n",
        "    pipe = Augmentor.Pipeline(path)           # Create pipeline in path of dataset\n",
        "    pipe.flip_left_right(1)                   # Horizontally flip every image\n",
        "    pipe.random_distortion(1, 5, 5, 4)        # Randomly distort flipped images\n",
        "    pipe.process()                            # Process images in pipeline\n",
        "\n",
        "# Geometric augmentation: rotate and shear\n",
        "def rotate_and_shear(path):\n",
        "    pipe = Augmentor.Pipeline(path)           # Create pipeline in path of dataset\n",
        "    pipe.rotate(1, 25, 25)                    # Rotate every image by 45 degrees\n",
        "    pipe.shear(1, 15, 15)                     # Randomly shear between 0 and 15 degrees\n",
        "    pipe.process()                            # Process images in pipeline\n",
        "\n",
        "# Move files between directories\n",
        "def move_files(augmented_path, dataset_path, new_file_name):\n",
        "    directory = listdir(augmented_path)\n",
        "    name_incrementer = 1\n",
        "    for file in directory:\n",
        "        move(augmented_path+'/'+file, dataset_path+'/'+new_file_name+'_'+str(name_incrementer)+'.jpg')\n",
        "        name_incrementer += 1\n",
        "        sleep(0.05)\n",
        "\n",
        "# ---------------------------- Split RealWaste ----------------------------- #\n",
        "print('\\n|----------------------------------| RealWaste Splitting |---------------------------------|\\n')\n",
        "\n",
        "# Split datasets\n",
        "for label in labels:\n",
        "    split_dataset(real_waste_original_path, real_waste_training_path, real_waste_validation_path, test_path, 0.2, 0.1, label)\n",
        "\n",
        "# Print file counts in paths\n",
        "for label in labels:\n",
        "    print('Number of files in RealWaste raw ' + label + ': ' + str(count_images(real_waste_original_path + label)))\n",
        "    print('Number of files in RealWaste training ' + label + ': ' + str(count_images(real_waste_training_path + label)))\n",
        "    print('Number of files in RealWaste validation ' + label + ': ' + str(count_images(real_waste_validation_path + label)))\n",
        "    print('Number of files in RealWaste test ' + label + ': ' + str(count_images(test_path + label)))\n",
        "    print()\n",
        "\n",
        "# ---------------------- Pre-Process Images RealWaste ---------------------- #\n",
        "print('|--------------------------------| RealWaste Pre-Processing |------------------------------|\\n')\n",
        "# Preprocess images\n",
        "for label in labels:\n",
        "    # RealWaste training\n",
        "    print('\\nBefore preprocessing RealWaste training ' + label + ': ' + str(count_images(real_waste_training_path + label)))\n",
        "    convert_rgb_images(real_waste_training_path+label)\n",
        "    resize_image(real_waste_training_path+label, img_width, img_height)\n",
        "    print('After preprocessing RealWaste training ' + label + ': ' + str(count_images(real_waste_training_path + label)))\n",
        "    \n",
        "    # RealWaste validation\n",
        "    print('Before preprocessing RealWaste validation ' + label + ': ' + str(count_images(real_waste_validation_path + label)))\n",
        "    convert_rgb_images(real_waste_validation_path+label)\n",
        "    resize_image(real_waste_validation_path+label, img_width, img_height)\n",
        "    print('After preprocessing RealWaste validation ' + label + ': ' + str(count_images(real_waste_validation_path + label)))\n",
        "    \n",
        "    # Testing\n",
        "    print('Before preprocessing test ' + label + ': ' + str(count_images(test_path + label)))\n",
        "    convert_rgb_images(test_path+label)\n",
        "    resize_image(test_path+label, img_width, img_height)\n",
        "    print('After preprocessing test ' + label + ': ' + str(count_images(test_path + label)))\n",
        "    print()\n",
        "\n",
        "# ---------------------- Distort and Flip RealWaste ------------------------ #\n",
        "print('|----------------------| RealWaste Augmentation - Distort and Flip |---------------------|\\n')\n",
        "\n",
        "# Perform augmentation\n",
        "for label in labels:\n",
        "    # RealWaste training\n",
        "    print('\\nTraining count RealWaste '+ label + ': ' + str(count_images(real_waste_training_path+label)))\n",
        "    distort_and_flip(real_waste_training_path+label)\n",
        "    print('Augmented training count RealWaste '+ label + ': ' + str(count_images(real_waste_training_path+label+'/output')))\n",
        "    sleep(60)\n",
        "    # RealWaste validation\n",
        "    print('\\nValidation count RealWaste '+ label + ': ' + str(count_images(real_waste_validation_path+label)))\n",
        "    distort_and_flip(real_waste_validation_path+label)\n",
        "    print('Augmented validation count RealWaste '+ label + ': ' + str(count_images(real_waste_validation_path+label+'/output')))\n",
        "    sleep(60)\n",
        "    # Move to temp directories\n",
        "    move_files(real_waste_training_path+label+'/output', temp_real_waste_training_path+label+'/', label+'_Distort_Flip')\n",
        "    sleep(60)\n",
        "    move_files(real_waste_validation_path+label+'/output', temp_real_waste_validation_path+label+'/', label+'_Distort_Flip')\n",
        "    sleep(60)\n",
        "    # Delete augmented output folder\n",
        "    rmdir(real_waste_training_path+label+'/output')\n",
        "    rmdir(real_waste_validation_path+label+'/output')\n",
        "\n",
        "# ---------------------- Rotate and Shear RealWaste ------------------------ #\n",
        "print('|---------------------| RealWaste Augmentation - Rotate and Shear |--------------------|\\n')\n",
        "\n",
        "# Perform augmentation\n",
        "for label in labels:\n",
        "    # RealWaste training\n",
        "    print('\\nTraining count RealWaste '+ label + ': ' + str(count_images(real_waste_training_path+label)))\n",
        "    rotate_and_shear(real_waste_training_path+label)\n",
        "    print('Augmented training count RealWaste '+ label + ': ' + str(count_images(real_waste_training_path+label+'/output')))\n",
        "    sleep(60)\n",
        "    # RealWaste validation\n",
        "    print('\\nValidation count RealWaste '+ label + ': ' + str(count_images(real_waste_validation_path+label)))\n",
        "    rotate_and_shear(real_waste_validation_path+label)\n",
        "    print('Augmented validation count RealWaste '+ label + ': ' + str(count_images(real_waste_validation_path+label+'/output')))\n",
        "    sleep(60)\n",
        "    # Move files back to container\n",
        "    move_files(real_waste_training_path+label+'/output', real_waste_training_path+label+'/', label+'_Rotate_Shear')\n",
        "    sleep(60)\n",
        "    move_files(real_waste_validation_path+label+'/output', real_waste_validation_path+label+'/', label+'_Rotate_Shear')\n",
        "    sleep(60)\n",
        "    # Delete augmented output folder\n",
        "    rmdir(real_waste_training_path+label+'/output')\n",
        "    rmdir(real_waste_validation_path+label+'/output')\n",
        "\n",
        "# Move first augmentation back to directory\n",
        "for label in labels:\n",
        "    move_files(temp_real_waste_training_path+label, real_waste_training_path+label, label+'_Distort_Flip')\n",
        "    sleep(60)\n",
        "    move_files(temp_real_waste_validation_path+label, real_waste_validation_path+label, label+'_Distort_Flip')\n",
        "    sleep(60)\n",
        "\n",
        "# Print final label counts\n",
        "print('Final training count RealWaste ' + label + ': ' + str(count_images(real_waste_training_path)))\n",
        "print('Final validation count RealWaste ' + label + ': ' + str(count_images(real_waste_validation_path)))\n",
        "print()\n",
        "\n",
        "# -------------------------- Print Final Counts ---------------------------- #\n",
        "# Print training counts for each label in training dataset\n",
        "print('\\n|-----------| Total Training Label Counts |-----------|')\n",
        "for label in labels:\n",
        "    print('RealWaste ' + label + ': ' + str(count_images(real_waste_training_path+label)))\n",
        "print('\\n')\n",
        "\n",
        "# Print validation counts for each label\n",
        "print('\\|----------| Total Validation Label Counts |----------|')\n",
        "for label in labels:\n",
        "    print('RealWaste ' + label + ': ' + str(count_images(real_waste_validation_path+label)))\n",
        "print('\\n')\n",
        "\n",
        "# Print testing counts for each label\n",
        "print('\\n|------------| Total Testing Label Counts |-----------|')\n",
        "for label in labels:\n",
        "    print('Test '+ label + ': ' + str(count_images(test_path+label)))\n",
        "\n",
        "# -------------------------- Disconnect Runtime ---------------------------- #\n",
        "runtime.unassign()   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tm9WVroyLb_L"
      },
      "source": [
        "# DiversionNet Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzZTxK61LfM2"
      },
      "outputs": [],
      "source": [
        "# Install augmentor library for geometric augmentations\n",
        "!pip install Augmentor\n",
        "# Import directory navigation libraries\n",
        "from os import listdir, rmdir\n",
        "# Import image preprocessing libraries\n",
        "import numpy as np\n",
        "import cv2\n",
        "from shutil import move, copy\n",
        "from random import randint\n",
        "from PIL import Image\n",
        "from tensorflow.image import resize\n",
        "from tensorflow.io import decode_jpeg, encode_jpeg, write_file\n",
        "from tensorflow.dtypes import saturate_cast\n",
        "from random import randint\n",
        "# Import augmentor for geometric data augmentations\n",
        "import Augmentor\n",
        "# Import Colab runtime disconnection\n",
        "from google.colab import runtime\n",
        "# Import sleep to allow time for copying to process\n",
        "from time import sleep\n",
        "\n",
        "# ------------------------------- Constants -------------------------------- #\n",
        "# Original dataset path\n",
        "diversion_net_original_path = ''\n",
        "# DiversionNet training and validation paths\n",
        "diversion_net_training_path = ''\n",
        "diversion_net_validation_path = ''\n",
        "# RealWaste temporary training and validation paths for augmentation stages\n",
        "temp_diversion_net_training_path = ''\n",
        "temp_diversion_net_validation_path = ''\n",
        "# Labels\n",
        "labels = ['Cardboard', 'Food Organics', 'Glass', 'Metal', 'Paper', 'Plastic', 'Miscellaneous Trash', 'Textile Trash', 'Vegetation']\n",
        "# Processed image dimensions\n",
        "img_height = 524\n",
        "img_width = 524\n",
        "\n",
        "# ------------------------------- Functions -------------------------------- #\n",
        "# Crop non-square images\n",
        "def crop_square(path, image, width, height, new_width, new_height, file):\n",
        "    top = (height - new_height)/2\n",
        "    bottom = (height + new_height)/2\n",
        "    left = (width - new_width)/2\n",
        "    right = (width + new_width)/2\n",
        "    cropped = image.crop((left, top, right, bottom))\n",
        "    cropped.save(path+'/'+file)\n",
        "    sleep(0.05)\n",
        "\n",
        "# Copy original images to dataset path and crop if required\n",
        "def copy_and_crop(path):\n",
        "    directory = listdir(path+' Raw')\n",
        "    for file in directory:\n",
        "        im = Image.open(path+' Raw/'+file)\n",
        "        new_height = 0\n",
        "        new_width = 0\n",
        "        width, height = im.size\n",
        "        if width > height:\n",
        "            crop_square(path, im, width, height, height, height, file)\n",
        "        elif height > width:\n",
        "            crop_square(path, im, width, height, width, width, file)\n",
        "        else:\n",
        "            copy(path+' Raw/'+file, path+'/'+file)\n",
        "            sleep(0.05)\n",
        "\n",
        "# Count images\n",
        "def count_images(path):\n",
        "    directory = listdir(path)\n",
        "    return len(directory)\n",
        "\n",
        "# Split training and validation datasets\n",
        "def split_dataset(input_path, train_path, val_path, val_prop, label):\n",
        "    # Count images in directory and get files names\n",
        "    num_files = count_images(input_path+label)\n",
        "    file_names = listdir(input_path+label)\n",
        "\n",
        "    # Calculated number of validation\n",
        "    num_val = round(num_files*val_prop)\n",
        "    \n",
        "    # Initialise empty lists for image indexes\n",
        "    val_list = []\n",
        "    \n",
        "    # Randomly assign file indexes for validation dataset\n",
        "    i = 0\n",
        "    while i < num_val:\n",
        "        r = randint(1, num_files - 1)\n",
        "        if r not in val_list:\n",
        "            val_list.append(r)\n",
        "            i += 1\n",
        "\n",
        "    # Move validation dataset files and rename\n",
        "    name_incrementer = 1\n",
        "    for j in val_list:\n",
        "        copy(input_path+label+'/'+file_names[j], val_path+label+'/'+label+'_'+str(name_incrementer)+'.jpg')\n",
        "        sleep(0.05)\n",
        "        name_incrementer += 1\n",
        "\n",
        "    # Move remaining files into training dataset\n",
        "    i = 0\n",
        "    name_incrementer = 1\n",
        "    while i < num_files:\n",
        "        if i not in val_list:\n",
        "            copy(input_path+label+'/'+file_names[i], train_path+label+'/'+label+'_'+str(name_incrementer)+'.jpg')\n",
        "            sleep(0.05)\n",
        "            name_incrementer += 1\n",
        "        i += 1\n",
        "\n",
        "# Resize images\n",
        "def resize_image(path, width, height):\n",
        "    directory = listdir(path)\n",
        "    for file in directory:\n",
        "        # Read image as binary file\n",
        "        binary_image = open(path+'/'+file, 'rb')                          \n",
        "        binary_representation = binary_image.read()                        \n",
        "        decoded_representation = decode_jpeg(binary_representation) \n",
        "        # Resize binary represnetation\n",
        "        resized_image = resize(decoded_representation, [width, height])\n",
        "        resized_image = saturate_cast(resized_image, 'uint8')\n",
        "        encoded_image = encode_jpeg(resized_image)                  \n",
        "        write_file(path+'/'+file, encoded_image)\n",
        "        sleep(0.05)\n",
        "\n",
        "# Check images for RGB mode and convert if required\n",
        "def convert_rgb_images(path):\n",
        "    print(path)\n",
        "    directory = listdir(path)\n",
        "    for file in directory:\n",
        "        img = Image.open(path+'/'+file)\n",
        "        # Convert to RGB mode if not already in format\n",
        "        if img.mode != 'RGB':\n",
        "            img.convert('RGB').save(path+'/'+file)\n",
        "            sleep(0.05)\n",
        "            \n",
        "# Geometric augmentation function: distort and flip\n",
        "def distort_and_flip(path):\n",
        "    pipe = Augmentor.Pipeline(path)           # Create pipeline in path of dataset\n",
        "    pipe.flip_left_right(1)                   # Horizontally flip every image\n",
        "    pipe.random_distortion(1, 5, 5, 4)        # Randomly distort flipped images\n",
        "    pipe.process()                            # Process images in pipeline\n",
        "\n",
        "# Geometric augmentation: rotate and shear\n",
        "def rotate_and_shear(path):\n",
        "    pipe = Augmentor.Pipeline(path)           # Create pipeline in path of dataset\n",
        "    pipe.rotate(1, 25, 25)                    # Rotate every image by 45 degrees\n",
        "    pipe.shear(1, 15, 15)                     # Randomly shear between 0 and 15 degrees\n",
        "    pipe.process()                            # Process images in pipeline\n",
        "\n",
        "# Move files between directories\n",
        "def move_files(augmented_path, dataset_path, new_file_name):\n",
        "    directory = listdir(augmented_path)\n",
        "    name_incrementer = 1\n",
        "    for file in directory:\n",
        "        move(augmented_path+'/'+file, dataset_path+'/'+new_file_name+'_'+str(name_incrementer)+'.jpg')\n",
        "        name_incrementer += 1\n",
        "        sleep(0.05)\n",
        "\n",
        "# -------------------------- Format DiversionNet --------------------------- #\n",
        "print('\\n|----------------------------------| DiversionNet Formatting |--------------------------------|\\n')\n",
        "\n",
        "# Format images by cropping if required\n",
        "for label in labels:\n",
        "    copy_and_crop(diversion_net_original_path+label)\n",
        "\n",
        "# -------------------------- Split DiversionNet ---------------------------- #\n",
        "print('|----------------------------------| DiversionNet Splitting |---------------------------------|\\n')\n",
        "\n",
        "# Split datasets\n",
        "for label in labels:\n",
        "    split_dataset(diversion_net_original_path, diversion_net_training_path, diversion_net_validation_path, 0.3, label)\n",
        "\n",
        "# Print file counts in paths\n",
        "for label in labels:\n",
        "    print('Number of files in DiversionNet raw ' + label + ': ' + str(count_images(diversion_net_original_path + label)))\n",
        "    print('Number of files in DiversionNet training ' + label + ': ' + str(count_images(diversion_net_training_path + label)))\n",
        "    print('Number of files in DiversionNet validation ' + label + ': ' + str(count_images(diversion_net_validation_path + label)))\n",
        "    print()\n",
        "\n",
        "# -------------------- Pre-Process Images DiversionNet --------------------- #\n",
        "print('|--------------------------------| DiversionNet Pre-Processing |------------------------------|\\n')\n",
        "# Preprocess images\n",
        "for label in labels:\n",
        "    # DiversionNet training\n",
        "    print('\\nBefore preprocessing DiversionNet training ' + label + ': ' + str(count_images(diversion_net_training_path + label)))\n",
        "    convert_rgb_images(diversion_net_training_path+label)\n",
        "    resize_image(diversion_net_training_path+label, img_width, img_height)\n",
        "    print('After preprocessing DiversionNet training ' + label + ': ' + str(count_images(diversion_net_training_path + label)))\n",
        "    \n",
        "    # DiversionNet validation\n",
        "    print('Before preprocessing DiversionNet validation ' + label + ': ' + str(count_images(diversion_net_validation_path + label)))\n",
        "    convert_rgb_images(diversion_net_validation_path+label)\n",
        "    resize_image(diversion_net_validation_path+label, img_width, img_height)\n",
        "    print('After preprocessing DiversionNet validation ' + label + ': ' + str(count_images(diversion_net_validation_path + label)))\n",
        "\n",
        "# --------------------- Distort and Flip DiversionNet ---------------------- #\n",
        "print('|----------------------| DiversionNet Augmentation - Distort and Flip |---------------------|\\n')\n",
        "\n",
        "# Perform augmentation\n",
        "for label in labels:\n",
        "    # DiversionNet training\n",
        "    print('\\nTraining count DiversionNet '+ label + ': ' + str(count_images(diversion_net_training_path+label)))\n",
        "    distort_and_flip(diversion_net_training_path+label)\n",
        "    print('Augmented training count DiversionNet '+ label + ': ' + str(count_images(diversion_net_training_path+label+'/output')))\n",
        "    sleep(60)\n",
        "    # DiversionNet validation\n",
        "    print('\\nValidation count DiversionNet '+ label + ': ' + str(count_images(diversion_net_validation_path+label)))\n",
        "    distort_and_flip(diversion_net_validation_path+label)\n",
        "    print('Augmented validation count DiversionNet '+ label + ': ' + str(count_images(diversion_net_validation_path+label+'/output')))\n",
        "    sleep(60)\n",
        "    # Move to temp directories\n",
        "    move_files(diversion_net_training_path+label+'/output', temp_diversion_net_training_path+label+'/', label+'_Distort_Flip')\n",
        "    sleep(60)\n",
        "    move_files(diversion_net_validation_path+label+'/output', temp_diversion_net_validation_path+label+'/', label+'_Distort_Flip')\n",
        "    sleep(60)\n",
        "    # Delete augmented output folder\n",
        "    rmdir(diversion_net_training_path+label+'/output')\n",
        "    rmdir(diversion_net_validation_path+label+'/output')\n",
        "\n",
        "# --------------------- Rotate and Shear DiversionNet ---------------------- #\n",
        "print('|---------------------| DiversionNet Augmentation - Rotate and Shear |--------------------|\\n')\n",
        "\n",
        "# Perform augmentation\n",
        "for label in labels:\n",
        "    # DiversionNet training\n",
        "    print('\\nTraining count DiversionNet '+ label + ': ' + str(count_images(diversion_net_training_path+label)))\n",
        "    rotate_and_shear(diversion_net_training_path+label)\n",
        "    print('Augmented training count DiversionNet '+ label + ': ' + str(count_images(diversion_net_training_path+label+'/output')))\n",
        "    sleep(60)\n",
        "    # DiversionNet validation\n",
        "    print('\\nValidation count DiversionNet '+ label + ': ' + str(count_images(diversion_net_validation_path+label)))\n",
        "    rotate_and_shear(diversion_net_validation_path+label)\n",
        "    print('Augmented validation count DiversionNet '+ label + ': ' + str(count_images(diversion_net_validation_path+label+'/output')))\n",
        "    sleep(60)\n",
        "    # Move files back to container\n",
        "    move_files(diversion_net_training_path+label+'/output', diversion_net_training_path+label+'/', label+'_Rotate_Shear')\n",
        "    sleep(60)\n",
        "    move_files(diversion_net_validation_path+label+'/output', diversion_net_validation_path+label+'/', label+'_Rotate_Shear')\n",
        "    sleep(60)\n",
        "    # Delete augmented output folder\n",
        "    rmdir(diversion_net_training_path+label+'/output')\n",
        "    rmdir(diversion_net_validation_path+label+'/output')\n",
        "\n",
        "# Move first augmentation back to directory\n",
        "for label in labels:\n",
        "    move_files(temp_diversion_net_training_path+label, diversion_net_training_path+label, label+'_Distort_Flip')\n",
        "    sleep(60)\n",
        "    move_files(temp_diversion_net_validation_path+label, diversion_net_validation_path+label, label+'_Distort_Flip')\n",
        "    sleep(60)\n",
        "\n",
        "# Print final label counts\n",
        "print('Final training count DiversionNet ' + label + ': ' + str(count_images(diversion_net_training_path)))\n",
        "print('Final validation count DiversionNet ' + label + ': ' + str(count_images(diversion_net_validation_path)))\n",
        "print()\n",
        "\n",
        "# --------------------------- Print Final Counts --------------------------- #\n",
        "# Print training counts for each label in training dataset\n",
        "print('\\n|-----------| Total Training Label Counts |-----------|')\n",
        "for label in labels:\n",
        "    print('DiversionNet ' + label + ': ' + str(count_images(diversion_net_training_path+label)))\n",
        "print('\\n')\n",
        "\n",
        "# Print validation counts for each label\n",
        "print('\\|----------| Total Validation Label Counts |----------|')\n",
        "for label in labels:\n",
        "    print('DiversionNet ' + label + ': ' + str(count_images(diversion_net_validation_path+label)))\n",
        "print('\\n')\n",
        "\n",
        "# -------------------------- Disconnect Runtime ---------------------------- #\n",
        "runtime.unassign()   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfsWdhcqiS7S"
      },
      "source": [
        "# DenseNet121"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H9KPE6xxqqNj"
      },
      "outputs": [],
      "source": [
        "# Import os library to navigate directories\n",
        "from os import listdir\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.densenet import DenseNet121\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "# Import Colab runtime disconnection\n",
        "from google.colab import runtime\n",
        "\n",
        "# ------------------------------- Constants -------------------------------- #\n",
        "# Split basic and advanced feature extraction layers\n",
        "split_layer = 143\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 16       # Batch size for gradient learning\n",
        "img_height = 524      # Image pixel height\n",
        "img_width = 524       # Image pixel width\n",
        "epochs = 500          # Arbitrarily large epoch size for convergence\n",
        "\n",
        "# Learning rates\n",
        "learn_rate_fc = 1e-4  # Fully connected layers\n",
        "learn_rate_fe1 = 1e-5 # Later feature extraction layers\n",
        "learn_rate_fe2 = 1e-5 # Early feature extraction layers\n",
        "\n",
        "# Callback to stop model training when model converges\n",
        "model_callback = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
        "\n",
        "# Dataset paths\n",
        "train_dir = ''\n",
        "validation_dir = ''\n",
        "best_model_path_fc = ''\n",
        "best_model_path_fe1 = ''\n",
        "best_model_path_fe2 = ''\n",
        "dataset_name = ''\n",
        "\n",
        "# ------------------------ Training Mode Functions ------------------------- #\n",
        "# Freeze fully connected layers\n",
        "def freeze_fully_connected(model):\n",
        "    # Loop through fully connected layers and freeze\n",
        "    i = 2\n",
        "    while i < len(model.layers):\n",
        "        model.layers[i].trainable = False\n",
        "        i += 1\n",
        "    return model\n",
        "\n",
        "# Unfreeze set of feature extraction layers\n",
        "def unfreeze_feature_extraction_block(model, start_layer, end_layer):  \n",
        "    # Loop through all feature extraction layers and freeze\n",
        "    j = 0\n",
        "    while j < len(model.layers[1].layers):\n",
        "        model.layers[1].layers[j].trainable = False\n",
        "        j += 1\n",
        "    # Loop through specified feature extraction layers and unfreeze\n",
        "    for k in range(start_layer, end_layer + 1, 1):\n",
        "        if str(model.layers[1].layers[k]).split('.')[3] != 'batch_normalization':\n",
        "            model.layers[1].layers[k].trainable = True\n",
        "        k += 1\n",
        "    return model\n",
        "\n",
        "# --------------------------- Build DenseNet121 ---------------------------- #\n",
        "# Create base DenseNet121 model:\n",
        "  # 524x524x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = DenseNet121(input_shape = (img_height, img_width, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of DenseNet121\n",
        "# 7x7 global average pooling layer\n",
        "global_average_pooling = GlobalAveragePooling2D()\n",
        "# Fully connected layer using softmax activation function for 8 labels\n",
        "classifier = Dense(units = 9, activation = 'softmax')\n",
        "\n",
        "# Connect input layer, base model and output classifier\n",
        "inputs = Input(shape = (img_height, img_width, 3)) # Input layer: 524x524x3 RGB images\n",
        "model = base_model(inputs)                         # Feature extraction layers of DenseNet121\n",
        "model = global_average_pooling(model)              # Fully connected layer: 7x7 global average pooling\n",
        "outputs = classifier(model)                        # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build DenseNet121 model\n",
        "dense_net_121 = Model(inputs, outputs, name = 'DenseNet121')\n",
        "\n",
        "# --------------- Train DenseNet121 Fully Connected Layers ----------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "dense_net_121.compile(\n",
        "    optimizer = Adam(learn_rate_fc),\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# ---------------- Train DenseNet121 Fully Connected Layers ---------------- #\n",
        "print('\\n|------------------------------| Training Fully Connected Layers |--------------------------------|\\n')\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint_fc = ModelCheckpoint(best_model_path_fc + '/densenet121-' + dataset_name + '-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "dense_net_121.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint_fc, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------------| Fully Connected Layers Training Complete |---------------------------|\\n')\n",
        "\n",
        "# ----------- Train DenseNet121 Later Feature Extraction Layers ------------ #\n",
        "print('|------------------------| Fine Tuning Later Feature Extraction Layers |--------------------------|\\n')\n",
        "\n",
        "# Load model with best accuracy\n",
        "print('Loading model with best accuracy...\\n')\n",
        "directory = listdir(best_model_path_fc)\n",
        "for file in directory:\n",
        "    best_model_name = file.replace('.hdf5', '')\n",
        "dense_net_121_fe1 = load_model(best_model_path_fc + '/' + best_model_name + '.hdf5')\n",
        "\n",
        "# Swap learning mode\n",
        "dense_net_121_fe1 = freeze_fully_connected(dense_net_121_fe1)\n",
        "dense_net_121_fe1 = unfreeze_feature_extraction_block(dense_net_121_fe1, split_layer, len(dense_net_121_fe1.layers[1].layers) - 1)\n",
        "\n",
        "# Define checkpoint to save best model\n",
        "best_model_checkpoint_fe1 = ModelCheckpoint(best_model_path_fe1 + '/' + best_model_name + '-fe1-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Decrease learning rate to reduce overfitting\n",
        "dense_net_121_fe1.optimizer = Adam(learn_rate_fe1)\n",
        "\n",
        "# Fine tune model\n",
        "dense_net_121_fe1.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [best_model_checkpoint_fe1, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------| Fine Tuning Later Feature Extraction Layers Complete |---------------------|\\n')\n",
        "\n",
        "# ----------- Train DenseNet121 Early Feature Extraction Layers ------------ #\n",
        "print('|------------------------| Fine Tuning Early Feature Extraction Layers |--------------------------|\\n')\n",
        "\n",
        "# Load model with best accuracy\n",
        "print('Loading model with best accuracy...\\n')\n",
        "directory = listdir(best_model_path_fe1)\n",
        "for file in directory:\n",
        "    best_model_name = file.replace('.hdf5', '')\n",
        "dense_net_121_fe2 = load_model(best_model_path_fe1 + '/' + best_model_name + '.hdf5')\n",
        "\n",
        "# Swap learning mode\n",
        "dense_net_121_fe2 = freeze_fully_connected(dense_net_121_fe2)\n",
        "dense_net_121_fe2 = unfreeze_feature_extraction_block(dense_net_121_fe2, 1, split_layer - 1)\n",
        "\n",
        "# Define checkpoint to save best model\n",
        "best_model_checkpoint_fe2 = ModelCheckpoint(best_model_path_fe2 + '/' + best_model_name + '-fe2-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Decrease learning rate to reduce overfitting\n",
        "dense_net_121_fe2.optimizer = Adam(learn_rate_fe2)\n",
        "\n",
        "# Fine tune model\n",
        "dense_net_121_fe2.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [best_model_checkpoint_fe2, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------| Fine Tuning Early Feature Extraction Layers Complete |---------------------|')\n",
        "\n",
        "# -------------------------- Disconnect Runtime ---------------------------- #\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vbhES6Pspyk"
      },
      "source": [
        "# Inception V3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHEKDXUWsvWM"
      },
      "outputs": [],
      "source": [
        "# Import os library to navigate directories\n",
        "from os import listdir\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "# Import Colab runtime disconnection\n",
        "from google.colab import runtime\n",
        "\n",
        "# ------------------------------- Constants -------------------------------- #\n",
        "# Split basic and advanced feature extraction layers\n",
        "split_layer = 249\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 32       # Batch size for gradient learning\n",
        "img_height = 524      # Image pixel height\n",
        "img_width = 524       # Image pixel width\n",
        "epochs = 500          # Arbitrarily large epoch size for convergence\n",
        "\n",
        "# Learning rates\n",
        "learn_rate_fc = 1e-5  # Fully connected layers\n",
        "learn_rate_fe1 = 1e-5 # Later feature extraction layers\n",
        "learn_rate_fe2 = 1e-5 # Early feature extraction layers\n",
        "\n",
        "# Callback to stop model training when model converges\n",
        "model_callback = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
        "\n",
        "# Dataset paths\n",
        "train_dir = ''\n",
        "validation_dir = ''\n",
        "best_model_path_fc = ''\n",
        "best_model_path_fe1 = ''\n",
        "best_model_path_fe2 = ''\n",
        "dataset_name = ''\n",
        "\n",
        "# ------------------------ Training Mode Functions ------------------------- #\n",
        "# Freeze fully connected layers\n",
        "def freeze_fully_connected(model):\n",
        "    # Loop through fully connected layers and freeze\n",
        "    i = 2\n",
        "    while i < len(model.layers):\n",
        "        model.layers[i].trainable = False\n",
        "        i += 1\n",
        "    return model\n",
        "\n",
        "# Unfreeze set of feature extraction layers\n",
        "def unfreeze_feature_extraction_block(model, start_layer, end_layer):  \n",
        "    # Loop through all feature extraction layers and freeze\n",
        "    j = 0\n",
        "    while j < len(model.layers[1].layers):\n",
        "        model.layers[1].layers[j].trainable = False\n",
        "        j += 1\n",
        "    # Loop through specified feature extraction layers and unfreeze\n",
        "    for k in range(start_layer, end_layer, 1):\n",
        "        if str(model.layers[1].layers[k]).split('.')[3] != 'batch_normalization':\n",
        "            model.layers[1].layers[k].trainable = True\n",
        "        k += 1\n",
        "    return model\n",
        "\n",
        "# ---------------------------- Build Inception V3 -------------------------- #\n",
        "# Create base Inception V3 model:\n",
        "  # 524x524x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = InceptionV3(input_shape = (img_height, img_width, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of Inception V3\n",
        "global_average_pool = GlobalAveragePooling2D()        # Global average pooling\n",
        "fc1 = Dense(units = 2048, activation = 'relu')        # 2048 neuron fully connected layer with ReLU activation\n",
        "classifier = Dense(units = 9, activation = 'softmax') # Softmax classifier\n",
        "\n",
        "# Connect input layer, base model and output layers\n",
        "inputs = Input(shape = (img_height, img_width, 3)) # Input layer: 224x224 RGB images\n",
        "model = base_model(inputs)                         # Feature extraction layers of Inception V3\n",
        "model = global_average_pool(model)                 # Global average pooling layer\n",
        "model = fc1(model)                                 # Fully connected layer: 2048 neuron ReLU\n",
        "outputs = classifier(model)                        # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build inception_v3 model\n",
        "inception_v3 = Model(inputs, outputs, name = 'InceptionV3')\n",
        "\n",
        "# --------------- Train Inception V3 Fully Connected Layers ---------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "inception_v3.compile(\n",
        "    optimizer = Adam(learn_rate_fc),\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# ---------------- Train Inception V3 Fully Connected Layers --------------- #\n",
        "print('\\n|------------------------------| Training Fully Connected Layers |--------------------------------|\\n')\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint_fc = ModelCheckpoint(best_model_path_fc + '/inception_v3-' + dataset_name + '-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "inception_v3.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint_fc, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------------| Fully Connected Layers Training Complete |---------------------------|\\n')\n",
        "\n",
        "# ----------- Train Inception V3 Later Feature Extraction Layers ----------- #\n",
        "print('|------------------------| Fine Tuning Later Feature Extraction Layers |--------------------------|\\n')\n",
        "\n",
        "# Load model with best accuracy\n",
        "print('Loading model with best accuracy...\\n')\n",
        "directory = listdir(best_model_path_fc)\n",
        "for file in directory:\n",
        "    best_model_name = file.replace('.hdf5', '')\n",
        "inception_v3_fe1 = load_model(best_model_path_fc + '/' + best_model_name + '.hdf5')\n",
        "\n",
        "# Swap learning mode\n",
        "inception_v3_fe1 = freeze_fully_connected(inception_v3_fe1)\n",
        "inception_v3_fe1 = unfreeze_feature_extraction_block(inception_v3_fe1, split_layer, len(inception_v3_fe1.layers[1].layers))\n",
        "\n",
        "# Define checkpoint to save best model\n",
        "best_model_checkpoint_fe1 = ModelCheckpoint(best_model_path_fe1 + '/' + best_model_name + '-fe1-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Decrease learning rate to reduce overfitting\n",
        "inception_v3_fe1.optimizer = Adam(learn_rate_fe1)\n",
        "\n",
        "# Fine tune model\n",
        "inception_v3_fe1.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [best_model_checkpoint_fe1, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------| Fine Tuning Later Feature Extraction Layers Complete |---------------------|\\n')\n",
        "\n",
        "# ----------- Train Inception V3 Early Feature Extraction Layers ----------- #\n",
        "print('|------------------------| Fine Tuning Early Feature Extraction Layers |--------------------------|\\n')\n",
        "\n",
        "# Load model with best accuracy\n",
        "print('Loading model with best accuracy...\\n')\n",
        "directory = listdir(best_model_path_fe1)\n",
        "for file in directory:\n",
        "    best_model_name = file.replace('.hdf5', '')\n",
        "inception_v3_fe2 = load_model(best_model_path_fe1 + '/' + best_model_name + '.hdf5')\n",
        "\n",
        "# Swap learning mode\n",
        "inception_v3_fe2 = freeze_fully_connected(inception_v3_fe2)\n",
        "inception_v3_fe2 = unfreeze_feature_extraction_block(inception_v3_fe2, 1, split_layer - 1)\n",
        "\n",
        "# Define checkpoint to save best model\n",
        "best_model_checkpoint_fe2 = ModelCheckpoint(best_model_path_fe2 + '/' + best_model_name + '-fe2-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Decrease learning rate to reduce overfitting\n",
        "inception_v3_fe2.optimizer = Adam(learn_rate_fe2)\n",
        "\n",
        "# Fine tune model\n",
        "inception_v3_fe2.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [best_model_checkpoint_fe2, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------| Fine Tuning Early Feature Extraction Layers Complete |---------------------|')\n",
        "\n",
        "# -------------------------- Disconnect Runtime ---------------------------- #\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OM6RL4Otf5W"
      },
      "source": [
        "# InceptionResNet V2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edYIAy7wtjym"
      },
      "outputs": [],
      "source": [
        "# Import os library to navigate directories\n",
        "from os import listdir\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, Flatten\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "# Import Colab runtime disconnection\n",
        "from google.colab import runtime\n",
        "\n",
        "# ------------------------------- Constants -------------------------------- #\n",
        "# Split basic and advanced feature extraction layers\n",
        "split_layer = 576\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 32       # Batch size for gradient learning\n",
        "img_height = 524      # Image pixel height\n",
        "img_width = 524       # Image pixel width\n",
        "epochs = 500          # Arbitrarily large epoch size for convergence\n",
        "\n",
        "# Learning rates\n",
        "learn_rate_fc = 1e-6  # Fully connected layers\n",
        "learn_rate_fe1 = 1e-6 # Later feature extraction layers\n",
        "learn_rate_fe2 = 1e-6 # Early feature extraction layers\n",
        "\n",
        "# Callback to stop model training when model converges\n",
        "model_callback = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
        "\n",
        "# Dataset paths\n",
        "train_dir = ''\n",
        "validation_dir = ''\n",
        "best_model_path_fc = ''\n",
        "best_model_path_fe1 = ''\n",
        "best_model_path_fe2 = ''\n",
        "dataset_name = ''\n",
        "\n",
        "# ------------------------ Training Mode Functions ------------------------- #\n",
        "# Freeze fully connected layers\n",
        "def freeze_fully_connected(model):\n",
        "    # Loop through fully connected layers and freeze\n",
        "    i = 2\n",
        "    while i < len(model.layers):\n",
        "        model.layers[i].trainable = False\n",
        "        i += 1\n",
        "    return model\n",
        "\n",
        "# Unfreeze set of feature extraction layers\n",
        "def unfreeze_feature_extraction_block(model, start_layer, end_layer):  \n",
        "    # Loop through all feature extraction layers and freeze\n",
        "    j = 0\n",
        "    while j < len(model.layers[1].layers):\n",
        "        model.layers[1].layers[j].trainable = False\n",
        "        j += 1\n",
        "    # Loop through specified feature extraction layers and unfreeze\n",
        "    for k in range(start_layer, end_layer, 1):\n",
        "        if str(model.layers[1].layers[k]).split('.')[3] != 'batch_normalization':\n",
        "            model.layers[1].layers[k].trainable = True\n",
        "        k += 1\n",
        "    return model\n",
        "\n",
        "# ---------------------- Build InceptionResNet V2 ------------------------ #\n",
        "# Create base InceptionResNet V2 model:\n",
        "  # 524x524x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = InceptionResNetV2(input_shape = (img_height, img_width, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of InceptionResNet V2\n",
        "# Flatten layer\n",
        "flatten = Flatten()\n",
        "# Fully connected layer using softmax activation function for 8 labels\n",
        "classifier = Dense(units = 9, activation = 'softmax')\n",
        "\n",
        "# Connect input layer, base model and output classifier\n",
        "inputs = Input(shape = (img_height, img_width, 3)) # Input layer: 524x524x3 RGB images\n",
        "model = base_model(inputs)                         # Feature extraction layers of InceptionResNet V2\n",
        "model = flatten(model)                             # Fully connected layer: flatten function\n",
        "outputs = classifier(model)                        # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build InceptionResNetV2 model\n",
        "inception_resnet_v2 = Model(inputs, outputs, name = 'InceptionResNetV2')\n",
        "\n",
        "# ----------- Train InceptionResNet V2 Fully Connected Layers ------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "inception_resnet_v2.compile(\n",
        "    optimizer = Adam(learn_rate_fc),\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# ------------ Train InceptionResNet V2 Fully Connected Layers ------------- #\n",
        "print('\\n|------------------------------| Training Fully Connected Layers |--------------------------------|\\n')\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint_fc = ModelCheckpoint(best_model_path_fc + '/inception_resnet_v2-' + dataset_name + '-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "inception_resnet_v2.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint_fc, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------------| Fully Connected Layers Training Complete |---------------------------|\\n')\n",
        "\n",
        "# ------- Train InceptionResNet V2 Later Feature Extraction Layers --------- #\n",
        "print('|------------------------| Fine Tuning Later Feature Extraction Layers |--------------------------|\\n')\n",
        "\n",
        "# Load model with best accuracy\n",
        "print('Loading model with best accuracy...\\n')\n",
        "directory = listdir(best_model_path_fc)\n",
        "for file in directory:\n",
        "    best_model_name = file.replace('.hdf5', '')\n",
        "inception_resnet_v2_fe1 = load_model(best_model_path_fc + '/' + best_model_name + '.hdf5')\n",
        "\n",
        "# Swap learning mode\n",
        "inception_resnet_v2_fe1 = freeze_fully_connected(inception_resnet_v2_fe1)\n",
        "inception_resnet_v2_fe1 = unfreeze_feature_extraction_block(inception_resnet_v2_fe1, split_layer, len(inception_resnet_v2_fe1.layers[1].layers))\n",
        "\n",
        "# Define checkpoint to save best model\n",
        "best_model_checkpoint_fe1 = ModelCheckpoint(best_model_path_fe1 + '/' + best_model_name + '-fe1-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Decrease learning rate to reduce overfitting\n",
        "inception_resnet_v2_fe1.optimizer = Adam(learn_rate_fe1)\n",
        "\n",
        "# Fine tune model\n",
        "inception_resnet_v2_fe1.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [best_model_checkpoint_fe1, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------| Fine Tuning Later Feature Extraction Layers Complete |---------------------|\\n')\n",
        "\n",
        "# -------- Train InceptionResNet V2 Early Feature Extraction Layers -------- #\n",
        "print('|------------------------| Fine Tuning Early Feature Extraction Layers |--------------------------|\\n')\n",
        "\n",
        "# Load model with best accuracy\n",
        "print('Loading model with best accuracy...\\n')\n",
        "directory = listdir(best_model_path_fe1)\n",
        "for file in directory:\n",
        "    best_model_name = file.replace('.hdf5', '')\n",
        "inception_resnet_v2_fe2 = load_model(best_model_path_fe1 + '/' + best_model_name + '.hdf5')\n",
        "\n",
        "# Swap learning mode\n",
        "inception_resnet_v2_fe2 = freeze_fully_connected(inception_resnet_v2_fe2)\n",
        "inception_resnet_v2_fe2 = unfreeze_feature_extraction_block(inception_resnet_v2_fe2, 1, split_layer - 1)\n",
        "\n",
        "# Define checkpoint to save best model\n",
        "best_model_checkpoint_fe2 = ModelCheckpoint(best_model_path_fe2 + '/' + best_model_name + '-fe2-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Decrease learning rate to reduce overfitting\n",
        "inception_resnet_v2_fe2.optimizer = Adam(learn_rate_fe2)\n",
        "\n",
        "# Fine tune model\n",
        "inception_resnet_v2_fe2.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [best_model_checkpoint_fe2, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------| Fine Tuning Early Feature Extraction Layers Complete |---------------------|\\n')\n",
        "\n",
        "# -------------------------- Disconnect Runtime ---------------------------- #\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFrXos0VtBGR"
      },
      "source": [
        "# MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpM7BxV9tCc1"
      },
      "outputs": [],
      "source": [
        "# Import os library to navigate directories\n",
        "from os import listdir\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "# Import Colab runtime disconnection\n",
        "from google.colab import runtime\n",
        "\n",
        "# ------------------------------- Constants -------------------------------- #\n",
        "# Split basic and advanced feature extraction layers\n",
        "split_layer = 149\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 4        # Batch size for gradient learning\n",
        "img_height = 524      # Image pixel height\n",
        "img_width = 524       # Image pixel width\n",
        "epochs = 500          # Arbitrarily large epoch size for convergence\n",
        "\n",
        "# Learning rates\n",
        "learn_rate_fc = 1e-5  # Fully connected layers\n",
        "learn_rate_fe1 = 1e-5 # Later feature extraction layers\n",
        "learn_rate_fe2 = 1e-5 # Early feature extraction layers\n",
        "\n",
        "# Callback to stop model training when model converges\n",
        "model_callback = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
        "\n",
        "# Dataset paths\n",
        "train_dir = ''\n",
        "validation_dir = ''\n",
        "best_model_path_fc = ''\n",
        "best_model_path_fe1 = ''\n",
        "best_model_path_fe2 = ''\n",
        "dataset_name = ''\n",
        "\n",
        "# ------------------------ Training Mode Functions ------------------------- #\n",
        "# Freeze fully connected layers\n",
        "def freeze_fully_connected(model):\n",
        "    # Loop through fully connected layers and freeze\n",
        "    i = 2\n",
        "    while i < len(model.layers):\n",
        "        model.layers[i].trainable = False\n",
        "        i += 1\n",
        "    return model\n",
        "\n",
        "# Unfreeze set of feature extraction layers\n",
        "def unfreeze_feature_extraction_block(model, start_layer, end_layer):  \n",
        "    # Loop through all feature extraction layers and freeze\n",
        "    j = 0\n",
        "    while j < len(model.layers[1].layers):\n",
        "        model.layers[1].layers[j].trainable = False\n",
        "        j += 1\n",
        "    # Loop through specified feature extraction layers and unfreeze\n",
        "    for k in range(start_layer, end_layer, 1):\n",
        "        if str(model.layers[1].layers[k]).split('.')[3] != 'batch_normalization':\n",
        "            model.layers[1].layers[k].trainable = True\n",
        "        k += 1\n",
        "    return model\n",
        "\n",
        "# ---------------------------- Build MobileNetV2 --------------------------- #\n",
        "# Create base MobileNetV2 model:\n",
        "  # 524x524x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = MobileNetV2(input_shape = (img_height, img_width, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of InceptionV3\n",
        "global_average_pool = GlobalAveragePooling2D()        # Global average pooling\n",
        "classifier = Dense(units = 9, activation = 'softmax') # 1000 neuron fully connected layer with ReLU activation\n",
        "\n",
        "# Connect input layer, base model and output layers\n",
        "inputs = Input(shape = (img_height, img_width, 3)) # Input layer: 524x524x3 RGB images\n",
        "model = base_model(inputs)                         # Feature extraction layers of InceptionV3\n",
        "model = global_average_pool(model)                 # Global average pooling layer\n",
        "outputs = classifier(model)                        # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build MobileNetV2 model\n",
        "mobile_net_v2 = Model(inputs, outputs, name = 'MobileNetV2')\n",
        "\n",
        "# --------------- Train MobileNetV2 Fully Connected Layers ---------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "mobile_net_v2.compile(\n",
        "    optimizer = Adam(learn_rate_fc),\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# ---------------- Train MobileNet V2 Fully Connected Layers --------------- #\n",
        "print('\\n|------------------------------| Training Fully Connected Layers |--------------------------------|\\n')\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint_fc = ModelCheckpoint(best_model_path_fc + '/mobilenet_v2-' + dataset_name + '-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "mobile_net_v2.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint_fc, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------------| Fully Connected Layers Training Complete |---------------------------|\\n')\n",
        "\n",
        "# ----------- Train MobileNet V2 Later Feature Extraction Layers ----------- #\n",
        "print('|------------------------| Fine Tuning Later Feature Extraction Layers |--------------------------|\\n')\n",
        "\n",
        "# Load model with best accuracy\n",
        "print('Loading model with best accuracy...\\n')\n",
        "directory = listdir(best_model_path_fc)\n",
        "for file in directory:\n",
        "    best_model_name = file.replace('.hdf5', '')\n",
        "mobile_net_v2_fe1 = load_model(best_model_path_fc + '/' + best_model_name + '.hdf5')\n",
        "\n",
        "# Swap learning mode\n",
        "mobile_net_v2_fe1 = freeze_fully_connected(mobile_net_v2_fe1)\n",
        "mobile_net_v2_fe1 = unfreeze_feature_extraction_block(mobile_net_v2_fe1, split_layer, len(mobile_net_v2_fe1.layers[1].layers))\n",
        "\n",
        "# Define checkpoint to save best model\n",
        "best_model_checkpoint_fe1 = ModelCheckpoint(best_model_path_fe1 + '/' + best_model_name + '-fe1-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Decrease learning rate to reduce overfitting\n",
        "mobile_net_v2_fe1.optimizer = Adam(learn_rate_fe1)\n",
        "\n",
        "# Fine tune model\n",
        "mobile_net_v2_fe1.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [best_model_checkpoint_fe1, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------| Fine Tuning Later Feature Extraction Layers Complete |---------------------|\\n')\n",
        "\n",
        "# ----------- Train MobileNet V2 Early Feature Extraction Layers ----------- #\n",
        "print('|------------------------| Fine Tuning Early Feature Extraction Layers |--------------------------|\\n')\n",
        "\n",
        "# Load model with best accuracy\n",
        "print('Loading model with best accuracy...\\n')\n",
        "directory = listdir(best_model_path_fe1)\n",
        "for file in directory:\n",
        "    best_model_name = file.replace('.hdf5', '')\n",
        "mobile_net_v2_fe2 = load_model(best_model_path_fe1 + '/' + best_model_name + '.hdf5')\n",
        "\n",
        "# Swap learning mode\n",
        "mobile_net_v2_fe2 = freeze_fully_connected(mobile_net_v2_fe2)\n",
        "mobile_net_v2_fe2 = unfreeze_feature_extraction_block(mobile_net_v2_fe2, 1, split_layer - 1)\n",
        "\n",
        "# Define checkpoint to save best model\n",
        "best_model_checkpoint_fe2 = ModelCheckpoint(best_model_path_fe2 + '/' + best_model_name + '-fe2-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Decrease learning rate to reduce overfitting\n",
        "mobile_net_v2_fe2.optimizer = Adam(learn_rate_fe2)\n",
        "\n",
        "# Fine tune model\n",
        "mobile_net_v2_fe2.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [best_model_checkpoint_fe2, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------| Fine Tuning Early Feature Extraction Layers Complete |---------------------|\\n')\n",
        "\n",
        "# -------------------------- Disconnect Runtime ---------------------------- #\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVJiM_KptaHm"
      },
      "source": [
        "# VGG-16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PB_uxEZtpHI"
      },
      "outputs": [],
      "source": [
        "# Import os library to navigate directories\n",
        "from os import listdir\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalAveragePooling2D\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import save_model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Import tensorflow functions for training\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.data import AUTOTUNE as autotune\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "# Import Colab runtime disconnection\n",
        "from google.colab import runtime\n",
        "\n",
        "# ------------------------------- Constants -------------------------------- #\n",
        "# Split basic and advanced feature extraction layers\n",
        "split_layer = 11\n",
        "\n",
        "# Training parameters\n",
        "batch_size = 4        # Batch size for gradient learning\n",
        "img_height = 524      # Image pixel height\n",
        "img_width = 524       # Image pixel width\n",
        "epochs = 500          # Arbitrarily large epoch size for convergence\n",
        "\n",
        "# Learning rates\n",
        "learn_rate_fc = 1e-5  # Fully connected layers\n",
        "learn_rate_fe1 = 1e-6 # Later feature extraction layers\n",
        "learn_rate_fe2 = 1e-6 # Early feature extraction layers\n",
        "\n",
        "# Callback to stop model training when model converges\n",
        "model_callback = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
        "\n",
        "# Dataset paths\n",
        "train_dir = ''\n",
        "validation_dir = ''\n",
        "best_model_path_fc = ''\n",
        "best_model_path_fe1 = ''\n",
        "best_model_path_fe2 = ''\n",
        "dataset_name = ''\n",
        "\n",
        "# ------------------------ Training Mode Functions ------------------------- #\n",
        "# Freeze fully connected layers\n",
        "def freeze_fully_connected(model):\n",
        "    # Loop through fully connected layers and freeze\n",
        "    i = 2\n",
        "    while i < len(model.layers):\n",
        "        model.layers[i].trainable = False\n",
        "        i += 1\n",
        "    return model\n",
        "\n",
        "# Unfreeze set of feature extraction layers\n",
        "def unfreeze_feature_extraction_block(model, start_layer, end_layer):  \n",
        "    # Loop through all feature extraction layers and freeze\n",
        "    j = 0\n",
        "    while j < len(model.layers[1].layers):\n",
        "        model.layers[1].layers[j].trainable = False\n",
        "        j += 1\n",
        "    # Loop through specified feature extraction layers and unfreeze\n",
        "    for k in range(start_layer, end_layer, 1):\n",
        "        if str(model.layers[1].layers[k]).split('.')[3] != 'batch_normalization':\n",
        "            model.layers[1].layers[k].trainable = True\n",
        "        k += 1\n",
        "    return model\n",
        "\n",
        "# ------------------------------ Build VGG-16 ------------------------------ #\n",
        "\n",
        "# Create base VGG-16 model:\n",
        "  # 524x524x3 input size\n",
        "  # Only feature extraction layers - no classification layers\n",
        "  # Feature extraction layer weights trained on ImageNet dataset\n",
        "base_model = VGG16(input_shape = (img_height, img_width, 3),\n",
        "                         include_top = False,\n",
        "                         weights = 'imagenet'\n",
        "                         )\n",
        "# Freeze learning on feature extraction layers\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create classification layers of VGG16\n",
        "# Global average pooling\n",
        "global_average_pooling = GlobalAveragePooling2D()\n",
        "# Fully connected layer 1: 4096 neurons ReLU activation function\n",
        "fc1 = Dense(units = 4096, activation = 'relu')\n",
        "# Fully connected layer 2: 4096 neurons ReLU activation function\n",
        "fc2 = Dense(units = 4096, activation = 'relu')\n",
        "# Classification layer: softmax layer with 8 neurons for class labels\n",
        "classifier = Dense(units = 9, activation = 'softmax')\n",
        "\n",
        "# Connect input layer, base model and output layers\n",
        "inputs = Input(shape = (img_height, img_width, 3)) # Input layer: 524x524x3 RGB images\n",
        "model = base_model(inputs)                         # Feature extraction layers of VGG-16\n",
        "model = global_average_pooling(model)              # Global average pooling layer\n",
        "model = fc1(model)                                 # Fully connected layer: 4096 neuron ReLU\n",
        "model = fc2(model)                                 # Fully connected layer: 4096 neuron ReLU\n",
        "outputs = classifier(model)                        # Fully connected layer: 8 neuron softmax activation for classification\n",
        "\n",
        "# Build VGG-16 model\n",
        "vgg16 = Model(inputs, outputs, name = 'VGG-16')\n",
        "\n",
        "# ------------------ Train VGG-16 Fully Connected Layers ------------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Create training dataset\n",
        "train_ds = image_dataset_from_directory(\n",
        "    train_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize training dataset pixel values to improve learning performance\n",
        "train_ds = train_ds.map(process)\n",
        "# Prefetch training dataset to improve computational speed\n",
        "train_ds = train_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Define validation dataset\n",
        "val_ds = image_dataset_from_directory(\n",
        "    validation_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (img_height, img_width),\n",
        "    batch_size = batch_size,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "# Normalize validation pixel values to improve learning performance\n",
        "val_ds = val_ds.map(process)\n",
        "# Prefetch validation dataset to improve computation speed\n",
        "val_ds = val_ds.cache().prefetch(buffer_size = autotune)\n",
        "\n",
        "# Compile model:\n",
        "  # Adam algorithm optimization\n",
        "  # Categorical crossentropy loss function for multilabel classification\n",
        "  # Metrics: accuracy, precision, recall\n",
        "vgg16.compile(\n",
        "    optimizer = Adam(learn_rate_fc),\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy', Precision(), Recall()]\n",
        ")\n",
        "\n",
        "# ------------------ Train VGG-16 Fully Connected Layers ------------------- #\n",
        "print('\\n|------------------------------| Training Fully Connected Layers |--------------------------------|\\n')\n",
        "\n",
        "# Define checkpoint to save model after every epoch\n",
        "model_checkpoint_fc = ModelCheckpoint(best_model_path_fc + '/vgg16-' + dataset_name + '-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Train model\n",
        "vgg16.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [model_checkpoint_fc, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------------| Fully Connected Layers Training Complete |---------------------------|\\n')\n",
        "\n",
        "# -------------- Train VGG-16 Later Feature Extraction Layers -------------- #\n",
        "print('|------------------------| Fine Tuning Later Feature Extraction Layers |--------------------------|\\n')\n",
        "\n",
        "# Load model with best accuracy\n",
        "print('Loading model with best accuracy...\\n')\n",
        "directory = listdir(best_model_path_fc)\n",
        "for file in directory:\n",
        "    best_model_name = file.replace('.hdf5', '')\n",
        "vgg16_fe1 = load_model(best_model_path_fc + '/' + best_model_name + '.hdf5')\n",
        "\n",
        "# Swap learning mode\n",
        "vgg16_fe1 = freeze_fully_connected(vgg16_fe1)\n",
        "vgg16_fe1 = unfreeze_feature_extraction_block(vgg16_fe1, split_layer, len(vgg16_fe1.layers[1].layers))\n",
        "\n",
        "# Define checkpoint to save best model\n",
        "best_model_checkpoint_fe1 = ModelCheckpoint(best_model_path_fe1 + '/' + best_model_name + '-fe1-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Decrease learning rate to reduce overfitting\n",
        "vgg16_fe1.optimizer = Adam(learn_rate_fe1)\n",
        "\n",
        "# Fine tune model\n",
        "vgg16_fe1.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [best_model_checkpoint_fe1, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------| Fine Tuning Later Feature Extraction Layers Complete |---------------------|\\n')\n",
        "\n",
        "# -------------- Train VGG-16 Early Feature Extraction Layers -------------- #\n",
        "print('|------------------------| Fine Tuning Early Feature Extraction Layers |--------------------------|\\n')\n",
        "\n",
        "# Load model with best accuracy\n",
        "print('Loading model with best accuracy...\\n')\n",
        "directory = listdir(best_model_path_fe1)\n",
        "for file in directory:\n",
        "    best_model_name = file.replace('.hdf5', '')\n",
        "vgg16_fe2 = load_model(best_model_path_fe1 + '/' + best_model_name + '.hdf5')\n",
        "\n",
        "# Swap learning mode\n",
        "vgg16_fe2 = freeze_fully_connected(vgg16_fe2)\n",
        "vgg16_fe2 = unfreeze_feature_extraction_block(vgg16_fe2, 1, split_layer - 1)\n",
        "\n",
        "# Define checkpoint to save best model\n",
        "best_model_checkpoint_fe2 = ModelCheckpoint(best_model_path_fe2 + '/' + best_model_name + '-fe2-{epoch:02d}-{val_accuracy:.4f}.hdf5', save_best_only = True, save_weights_only = False, mode= 'auto')\n",
        "\n",
        "# Decrease learning rate to reduce overfitting\n",
        "vgg16_fe2.optimizer = Adam(learn_rate_fe2)\n",
        "\n",
        "# Fine tune model\n",
        "vgg16_fe2.fit(\n",
        "    train_ds,\n",
        "    validation_data = val_ds,\n",
        "    epochs = epochs,\n",
        "    verbose = 1,\n",
        "    callbacks = [best_model_checkpoint_fe2, model_callback]\n",
        ")\n",
        "\n",
        "print('\\n|--------------------| Fine Tuning Early Feature Extraction Layers Complete |---------------------|\\n')\n",
        "\n",
        "# -------------------------- Disconnect Runtime ---------------------------- #\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oObiuAPSwWGu"
      },
      "source": [
        "# Model Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyg9Oce7waGd"
      },
      "outputs": [],
      "source": [
        "# Import directory navigation\n",
        "from os import listdir\n",
        "# Import tensorflow libraries for loading models and testing dataset\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras import Model\n",
        "# Import Colab runtime disconnection\n",
        "from google.colab import runtime\n",
        "\n",
        "# Constants for model file paths\n",
        "base_model_paths = []\n",
        "models = ['DenseNet121', 'Inception V3', 'InceptionResNet V2', 'MobileNetV2', 'VGG-16']\n",
        "training_cycles = ['1 - Fully Connected Training', '2 - Advanced Feature Extraction Training', '3 - Basic Feature Extraction Training']\n",
        "test_dir = ''\n",
        "\n",
        "# -------------------------- Load Testing Dataset -------------------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Define testing dataset\n",
        "test_ds = image_dataset_from_directory(\n",
        "    test_dir,\n",
        "    validation_split = 0,\n",
        "    seed = 123,\n",
        "    image_size = (524, 524),\n",
        "    batch_size = 1,\n",
        "    label_mode = 'categorical'\n",
        ")\n",
        "test_ds = test_ds.map(process)\n",
        "\n",
        "# --------------------- Dataset and Testing Functions ---------------------- #\n",
        "def test_models(model_path, test):\n",
        "    # Loop through training cycles\n",
        "    for cycle in training_cycles:\n",
        "        print(cycle)\n",
        "\n",
        "        # Get directory of model\n",
        "        directory = listdir(model_path+'/'+cycle)\n",
        "        best_model = ''\n",
        "\n",
        "        if directory:\n",
        "            # Get best model name\n",
        "            for file in directory:\n",
        "                best_model = file\n",
        "\n",
        "            print(model_path+'/'+best_model)\n",
        "            \n",
        "            # Test best model and print results\n",
        "            model = load_model(model_path+'/'+cycle+'/'+best_model)\n",
        "            loss, accuracy, precision, recall = model.evaluate(test)\n",
        "        print()\n",
        "\n",
        "# ---------------------------- Testing Models ------------------------------ #\n",
        "# Test DiversionNet training\n",
        "print('\\n# --------------------------- Experiment 1 - DiversionNet Training ---------------------------- #\\n')\n",
        "for model in models:\n",
        "    print(model)\n",
        "    test_models(base_model_paths[0]+'/'+model, test_ds)\n",
        "\n",
        "# Test RealWaste training\n",
        "print('\\n# ---------------------------- Experiment 2 - RealWaste Training ------------------------------ #\\n')\n",
        "for model in models:\n",
        "    print(model)\n",
        "    test_models(base_model_paths[1]+'/'+model, test_ds)\n",
        "\n",
        "# -------------------------- Disconnect Runtime ---------------------------- #\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WFFCMzjYzRn"
      },
      "source": [
        "# Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAMYO8nvpPpw"
      },
      "outputs": [],
      "source": [
        "# Import directory navigation\n",
        "from os import listdir\n",
        "# Import tensorflow libraries for loading models and testing dataset\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for metrics\n",
        "from tensorflow.keras.metrics import Accuracy, Precision, Recall\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras import Model\n",
        "# Import Colab runtime disconnection\n",
        "from google.colab import runtime\n",
        "\n",
        "# Constants for model file paths\n",
        "model_path = ''\n",
        "test_dir = ''\n",
        "# Constants for labels\n",
        "labels = ['Cardboard', 'Food Organics', 'Glass', 'Metal', 'Miscellaneous Trash', 'Paper', 'Plastic', 'Textile Trash', 'Vegetation']\n",
        "num_labels = 9\n",
        "# Image dimensions\n",
        "img_width = 524\n",
        "img_height = 524\n",
        "# Matrix for storing predictions for each label\n",
        "label_counts = [[0,0,0,0,0,0,0,0,0],\n",
        "                [0,0,0,0,0,0,0,0,0],\n",
        "                [0,0,0,0,0,0,0,0,0],\n",
        "                [0,0,0,0,0,0,0,0,0],\n",
        "                [0,0,0,0,0,0,0,0,0],\n",
        "                [0,0,0,0,0,0,0,0,0],\n",
        "                [0,0,0,0,0,0,0,0,0],\n",
        "                [0,0,0,0,0,0,0,0,0],\n",
        "                [0,0,0,0,0,0,0,0,0]]\n",
        "\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Loop through testing label datasets and return results\n",
        "def test_label(label):\n",
        "    print('Testing ' + label + ' images...')\n",
        "    \n",
        "    # Empty array for prediction counts\n",
        "    predictions_count = [0,0,0,0,0,0,0,0,0]\n",
        "\n",
        "    # Define testing dataset for with only single label populated\n",
        "    test_ds = image_dataset_from_directory(\n",
        "        test_dir+label,\n",
        "        validation_split = 0,\n",
        "        image_size = (img_width, img_height),\n",
        "        batch_size = 1,\n",
        "        label_mode = 'categorical'\n",
        "    )\n",
        "\n",
        "    # Normalize RGB values of pixels\n",
        "    test_ds = test_ds.map(process)\n",
        "    \n",
        "    # Load model\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    # Run model over testing label dataset\n",
        "    results = model.predict(test_ds)\n",
        "    \n",
        "    # Parse results\n",
        "    for result in results:\n",
        "        index = 0\n",
        "        probability = 0\n",
        "        for j in range(0, num_labels):\n",
        "            if result[j] > probability:\n",
        "                index = j\n",
        "                probability = result[j]\n",
        "        predictions_count[index] += 1\n",
        "    print()\n",
        "    # Return predictions count for each label over label testing dataset\n",
        "    return predictions_count\n",
        "\n",
        "# ---------------------------- Run Label Tests ----------------------------- #\n",
        "# Run tests over each label dataset and populate results matrix\n",
        "for index in range(0, num_labels):\n",
        "    label_counts[index] = test_label(labels[index])\n",
        "print()\n",
        "\n",
        "# Print arrays for each label predictions\n",
        "for index in range(0, num_labels):\n",
        "    print(labels[index] + ': ' + str(label_counts[index]))\n",
        "\n",
        "# -------------------------- Disconnect Runtime ---------------------------- #\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQxC4B5gpRGd"
      },
      "source": [
        "# Mislabel Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yV432kBHptnn"
      },
      "outputs": [],
      "source": [
        "# Import directory navigation\n",
        "from os import listdir\n",
        "# Import tensorflow libraries for loading models and testing dataset\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow import cast\n",
        "# Import tensorflow functions for model building\n",
        "from tensorflow.keras import Model\n",
        "# Import argmax to get index of maximum value\n",
        "from numpy import argmax\n",
        "# Import Colab runtime disconnection\n",
        "from google.colab import runtime\n",
        "\n",
        "# -------------------------------- Constant -------------------------------- #\n",
        "# Constants for model file paths\n",
        "model_path = ''\n",
        "test_dir_base = ''\n",
        "# Constants for labels\n",
        "labels = ['Cardboard', 'Food Organics', 'Glass', 'Metal', 'Miscellaneous Trash', 'Paper', 'Plastic', 'Textile Trash', 'Vegetation']\n",
        "num_labels = 9\n",
        "# Image dimensions\n",
        "img_width = 524\n",
        "img_height = 524\n",
        "# Matrix for storing mislabelled images\n",
        "mislabel_paths = [[], [], [], [], [], [], [], [], []]\n",
        "\n",
        "# -------------------------------- Functions ------------------------------- #\n",
        "# RGB value normalization to improve learning rate - RGB values within activation function range\n",
        "def process(image, label):\n",
        "    image = cast(image/255.0, 'float32')\n",
        "    return image, label\n",
        "\n",
        "# Test images in path and return confusion and incorrect labelling\n",
        "def test_label(label, label_index):\n",
        "    print('Testing ' + label + ' images...\\n')\n",
        "    \n",
        "    # Empty array for mislabels\n",
        "    mislabels = []\n",
        "\n",
        "    # Load model and test label directory\n",
        "    model = load_model(model_path)\n",
        "    img_count = len(listdir(test_dir_base+label))\n",
        "\n",
        "    # Test each image and store results\n",
        "    for temp_count in range(1, img_count + 1):\n",
        "        # Define testing dataset\n",
        "        test_dir = test_dir_base + label + '/' + str(temp_count)\n",
        "        test_ds = image_dataset_from_directory(\n",
        "            test_dir,\n",
        "            validation_split = 0,\n",
        "            image_size = (img_width, img_height),\n",
        "            batch_size = 1,\n",
        "            label_mode = 'categorical'\n",
        "        )\n",
        "        test_ds = test_ds.map(process)\n",
        "        \n",
        "        result = model.predict(test_ds)\n",
        "\n",
        "        if (argmax(result) != label_index):\n",
        "            mislabels.append(test_dir+label+'/'+label)\n",
        "            print('\\n'+test_dir+label+'/'+str(temp_count)+'/'+label+' predicted as: '+labels[argmax(result)])\n",
        "\n",
        "    # Set values in global arrays for mislabels\n",
        "    mislabel_paths[label_index] = mislabels\n",
        "\n",
        "# ------------ Calculate Confusion Matrix and Print Mislabels -------------- #\n",
        "# Run testing\n",
        "label_index = 0\n",
        "for label in labels:\n",
        "    test_label(label, label_index)\n",
        "    label_index += 1\n",
        "    print()\n",
        "\n",
        "# Print arrays for each label predictions\n",
        "for index in range(0, num_labels):\n",
        "    print('|--------------------------| '+labels[index]+' |--------------------------|\\n')\n",
        "    for mislabel in mislabel_paths[index]:\n",
        "        print(mislabel)\n",
        "    print()\n",
        "\n",
        "# -------------------------- Disconnect Runtime ---------------------------- #\n",
        "runtime.unassign()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMkk/JZHKuEaMgvc69AEbJh",
      "collapsed_sections": [
        "pfsWdhcqiS7S",
        "4vbhES6Pspyk",
        "-OM6RL4Otf5W",
        "xFrXos0VtBGR",
        "aVJiM_KptaHm",
        "oObiuAPSwWGu",
        "9WFFCMzjYzRn"
      ],
      "gpuType": "V100",
      "machine_shape": "hm",
      "mount_file_id": "1sGiVwXPHRnIFAUHk65K5BVC598Gbs1Gs",
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
